// server.js
require('dotenv').config();            // optional, if you use a .env
const express   = require('express');
const http      = require('http');
const WebSocket = require('ws');
const cors      = require('cors');
const axios     = require('axios');

const app    = express();
const server = http.createServer(app);
const port   = process.env.PORT || 10000;

app.use(cors());

// â”€â”€â”€ Health Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.get('/', (req, res) => {
  console.log('ğŸ” [Health] GET / â†’ OK');
  res.send('âœ… AI Call Server is live');
});

// â”€â”€â”€ TwiML Endpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.all('/twiml', (req, res) => {
  const { agent_id, voice_id, contact_name, address } = req.query;
  console.log('â¡ï¸ [TwiML] Received:', req.query);

  if (!agent_id || !voice_id || !contact_name || !address) {
    console.error('âŒ [TwiML] missing required fields');
    return res.status(400).send('Missing required fields');
  }

  // Build WS URL (no params hereâ€”Twilio will inject them via <Parameter/>)
  const rawWsUrl = `wss://${req.headers.host}/media`;
  // Escape & just in case
  const xmlSafeWsUrl = rawWsUrl.replace(/&/g, '&amp;');

  // TwiML with Connectâ†’Stream+Parameters
  const twiml = `
    <Response>
      <Connect>
        <Stream url="${xmlSafeWsUrl}">
          <Parameter name="agent_id"     value="${agent_id}" />
          <Parameter name="voice_id"     value="${voice_id}" />
          <Parameter name="contact_name" value="${contact_name}" />
          <Parameter name="address"      value="${address}" />
        </Stream>
      </Connect>
      <!-- put the caller on quiet hold while TTS streams -->
      <Pause length="60"/>
    </Response>`.trim();

  console.log('ğŸ”— [TwiML] sending Connect/Stream w/ params:', {
    agent_id, voice_id, contact_name, address
  });

  res.set('Content-Type', 'text/xml');
  res.send(twiml);
});

// â”€â”€â”€ WebSocket Server â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const wss = new WebSocket.Server({ noServer: true });

server.on('upgrade', (req, socket, head) => {
  if (req.url.startsWith('/media')) {
    console.log('ğŸ”„ [Upgrade] incoming WS upgrade to', req.url);
    wss.handleUpgrade(req, socket, head, ws => {
      wss.emit('connection', ws, req);
    });
  } else {
    socket.destroy();
  }
});

wss.on('connection', (ws /*, req */) => {
  console.log('âœ… [WebSocket] connected');

  ws.on('message', async raw => {
    let msg;
    try {
      msg = JSON.parse(raw.toString());
    } catch (e) {
      console.warn('âš ï¸ [WebSocket] non-JSON message, ignoring');
      return;
    }

    console.log('ğŸ“¡ [WebSocket] got event:', msg.event);

    // â€” handle the â€œstartâ€ event (should carry your <Parameter/> values)
    if (msg.event === 'start') {
      const params = msg.customParameters || msg.customparameters || {};
      console.log('   â€¢ callSid:', msg.streamSid || msg.callSid);
      console.log('   â€¢ parameters:', params);

      const { agent_id, voice_id, contact_name, address } = params;
      if (!agent_id || !voice_id || !contact_name || !address) {
        console.error('âŒ [WebSocket] missing parameters â†’ closing', params);
        return ws.close();
      }

      // Now kick off your ElevenLabs TTS â†’ send Î¼-law chunks back on ws.send(...)
      const text = `Hi ${contact_name}, just confirming your appointment at ${address}.`;
      console.log('ğŸ“ [TTS] generating:', text);

      try {
        const elevenKey = process.env.ELEVENLABS_API_KEY;
        const resp = await axios({
          method: 'post',
          url: `https://api.elevenlabs.io/v1/text-to-speech/${voice_id}/stream`,
          headers: {
            'xi-api-key': elevenKey,
            'Content-Type': 'application/json',
            'Accept': 'audio/mulaw'
          },
          responseType: 'stream',
          data: {
            text,
            model_id: 'eleven_monolingual_v1',
            voice_settings: { stability: 0.4, similarity_boost: 0.75 }
          }
        });

        resp.data.on('data', chunk => {
          console.log(`ğŸ“¦ [TTS] sending ${chunk.length} bytes`);
          ws.send(chunk);
        });
        resp.data.on('end', () => {
          console.log('âœ… [TTS] done, closing WS');
          ws.close();
        });
      } catch (err) {
        console.error('âŒ [TTS] ElevenLabs error:', err.response?.status, err.message);
        ws.close();
      }

    // â€” optional: log inbound media frames if you ever want speech recognition
    } else if (msg.event === 'media') {
      // console.log('ğŸ™ [WebSocket] inbound media, length=', msg.media.payload.length);
    }
  });

  ws.on('close',   (code, reason) => console.log('ğŸ›‘ [WebSocket] closed', code, reason));
  ws.on('error',   err          => console.error('ğŸ’¥ [WebSocket] error', err.message));
});

server.listen(port, () => {
  console.log(`ğŸš€ AI Call Server running on port ${port}`);
});
